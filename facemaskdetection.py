# -*- coding: utf-8 -*-
"""FaceMaskDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10uD-VO4CxO9TIQ3l0dbWj0USrFiFrydh
"""

import numpy as np
import pandas as pd

pd.set_option('display.max_columns', None)

from zipfile import ZipFile
file_name = '/content/FaceMaskDetection.zip'

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')

"""What below Code Does: Parses XML Files:

1. Extracts image filename, dimensions, and bounding box coordinates.

2. Extracts class labels (class_name).

3. Stores Data: pandass dataframs(annotations.csv)


"""

import os
import xml.etree.ElementTree as ET
import pandas as pd
from PIL import Image

# Paths to your dataset
image_dir = '/content/images'  # Folder containing images
annotation_dir = '/content/annotations'  # Folder containing XML files

# Initialize lists to store data
data = []

# Parse each XML file
for xml_file in os.listdir(annotation_dir):
    if xml_file.endswith('.xml'):
        xml_path = os.path.join(annotation_dir, xml_file)
        tree = ET.parse(xml_path)
        root = tree.getroot()

        # Extract image information
        filename = root.find('filename').text
        width = int(root.find('size/width').text)
        height = int(root.find('size/height').text)

        # Extract object information
        for obj in root.findall('object'):
            class_name = obj.find('name').text
            xmin = int(obj.find('bndbox/xmin').text)
            ymin = int(obj.find('bndbox/ymin').text)
            xmax = int(obj.find('bndbox/xmax').text)
            ymax = int(obj.find('bndbox/ymax').text)

            # Append to data list
            data.append([filename, width, height, class_name, xmin, ymin, xmax, ymax])

# Convert to DataFrame
columns = ['filename', 'width', 'height', 'class_name', 'xmin', 'ymin', 'xmax', 'ymax']
df = pd.DataFrame(data, columns=columns)

# Display the first few rows
print(df.head())

# Save the DataFrame to CSV for future use
df.to_csv('annotations.csv', index=False)

# for i in df.columns:
#   print("Column Name=", i)
#   print(df[i].value_counts().sort_values(ascending=False))
#   print("---------------------------------------------------------------------------------------------------------------")

df['class_name'].value_counts()

import matplotlib.pyplot as plt

# col_name = 'Column1'
# null_count = df[col_name].isnull().sum()    # Count of null values
# non_null_count = df[col_name].notnull().sum()  # Count of non-null values


labels = ['With_Mask', 'Without_Mask', 'Mask_Weared_Incorrectly']
sizes = [df[df['class_name']=='with_mask'].shape[0], df[df['class_name']=='without_mask'].shape[0], df[df['class_name']=='mask_weared_incorrect'].shape[0]]
colors = ['blue','red', 'green']


plt.figure(figsize=(6, 6))
plt.pie(sizes, labels=labels, autopct='%1.2f%%', colors=colors, startangle=140, wedgeprops={'edgecolor': 'black'})
plt.title(f"Distribution of Values in Masks Column")
plt.show()

"""Q. What this part of code does?


```
plt.text(bar.get_x() + bar.get_width() /2
    bar.get_height(),
    int(bar.get_height()),
    ha='center', va='bottom', fontsize=12, fontweight='bold'
    )
```



This will ensure the count values appear clearly on top of each bar.
"""

class_counts = df['class_name'].value_counts()
plt.figure(figsize=(8, 5))
bars = class_counts.plot(kind='bar', color=['green', 'red', 'orange'])
plt.title('Class Distribution')
plt.xlabel('Distribution of Masked class')
plt.ylabel('Count')
# plt.legend()

for bar in bars.patches:
    plt.text(bar.get_x() + bar.get_width() / 2,
             bar.get_height(),
             int(bar.get_height()),
             ha='center', va='bottom', fontsize=12, fontweight='bold')

plt.show()

"""# Preprocessing and EDA

1. Visualize Samples with Bounding Boxes:
"""

import cv2
import matplotlib.pyplot as plt
import random

def visualize_samples(df, image_dir, num_samples=5):
    """Visualize random samples with bounding boxes"""
    plt.figure(figsize=(15, 10))
    for i in range(num_samples):
        # Randomly select a sample
        sample = df.sample(1).iloc[0]
        image_path = os.path.join(image_dir, sample['filename'])
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display

        # Draw bounding box
        xmin, ymin, xmax, ymax = sample['xmin'], sample['ymin'], sample['xmax'], sample['ymax']
        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
        cv2.putText(image, sample['class_name'], (xmin, ymin-10),
                     cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

        # Plot
        plt.subplot(1, num_samples, i+1)
        plt.imshow(image)
        plt.axis('off')
        plt.title(sample['filename'])
    plt.show()

# Visualize 5 random samples
visualize_samples(df, image_dir)

"""Reason for this output:
See, there are multiple objects in each xml file. We are only showing 1 person in each xml file. That's why we have this kind off output. Also, it keeps the image less messy.

However, if we want to show all annotations, here's the code.
"""

def visualize_all_boxes(df, image_dir, num_samples=5):
    """Visualize all bounding boxes in random samples"""
    plt.figure(figsize=(15, 10))
    for i in range(num_samples):
        # Randomly select an image
        image_name = df['filename'].sample(1).iloc[0]
        image_path = os.path.join(image_dir, image_name)
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display

        # Get all objects in the image
        objects_in_image = df[df['filename'] == image_name]

        # Draw all bounding boxes
        for _, obj in objects_in_image.iterrows():
            xmin, ymin, xmax, ymax = obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax']
            class_name = obj['class_name']

            # Assign different colors for each class
            if class_name == 'with_mask':
                color = (0, 255, 0)  # Green
            elif class_name == 'without_mask':
                color = (0, 0, 255)  # Red
            else:
                color = (255, 165, 0)  # Orange

            # Draw bounding box and label
            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)
            cv2.putText(image, class_name, (xmin, ymin-10),
                         cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

        # Plot
        plt.subplot(1, num_samples, i+1)
        plt.imshow(image)
        plt.axis('off')
        plt.title(image_name)
    plt.show()

# Visualize 5 random images with all bounding boxes
visualize_all_boxes(df, image_dir)

"""2. Analyse Image Sizes"""

# Check image dimensions
image_sizes = df[['width', 'height']].drop_duplicates()
print("Unique image sizes:")
print(image_sizes)

# Plot image size distribution
plt.figure(figsize=(10, 5))
plt.scatter(df['width'], df['height'], alpha=0.5)
plt.title('Image Size Distribution')
plt.xlabel('Width')
plt.ylabel('Height')
plt.show()

"""3. Prepare the image for applying algorithms"""

def prepare_cnn_dataset(df, image_dir, output_dir='dataset_cnn'):
    """Crop all faces and organize into class-specific folders"""
    os.makedirs(output_dir, exist_ok=True)

    for image_name in df['filename'].unique():
        # Load image
        image_path = os.path.join(image_dir, image_name)
        image = cv2.imread(image_path)

        # Get all objects in the image
        objects_in_image = df[df['filename'] == image_name]

        for _, obj in objects_in_image.iterrows():
            # Crop face
            xmin, ymin, xmax, ymax = obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax']
            face = image[ymin:ymax, xmin:xmax]

            # Save cropped face
            class_dir = os.path.join(output_dir, obj['class_name'])
            os.makedirs(class_dir, exist_ok=True)
            output_path = os.path.join(class_dir, f"{image_name}_{xmin}_{ymin}.jpg")
            cv2.imwrite(output_path, face)

# Prepare dataset for CNN
prepare_cnn_dataset(df, image_dir)

df['class_name'].value_counts()

"""Imbalance Handling"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import numpy as np
from sklearn.utils.class_weight import compute_class_weight

# Paths
dataset_path = 'dataset_cnn'
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

"""Data Augmentation Setup"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Paths
dataset_path = 'dataset_cnn'
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)

# No augmentation for validation
val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Training dataset
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

# Validation dataset
val_generator = val_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

"""Verify LAbels"""

# Check training generator
for x, y in train_generator:
    print("Training batch - X shape:", x.shape, "Y shape:", y.shape)
    break

# Check validation generator
for x, y in val_generator:
    print("Validation batch - X shape:", x.shape, "Y shape:", y.shape)
    break

"""Model Architecture"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model

def build_model():
    base_model = MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=(224, 224, 3)
    )

    # Freeze base layers
    base_model.trainable = False

    # Custom head
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)
    outputs = Dense(3, activation='softmax')(x)  # 3 classes

    model = Model(inputs=base_model.input, outputs=outputs)

    model.compile(
        optimizer=tf.keras.optimizers.Adam(0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

model = build_model()
model.summary()

"""Class weight calculation"""

# import numpy as np

# Class counts from your dataset
class_counts = {
    'with_mask': 3232,
    'without_mask': 717,
    'mask_weared_incorrect': 123
}

# Calculate class weights
total = sum(class_counts.values())
class_weights = {i: total/(len(class_counts)*count)
                for i, (cls, count) in enumerate(class_counts.items())}

print("Class Weights:", class_weights)

"""Training Configurations"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Callbacks
callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ModelCheckpoint('best_model.h5', save_best_only=True)
]

# Train the model
history = model.fit(
    train_generator,
    # epochs=20,
    epochs = 2,
    validation_data=val_generator,
    class_weight=class_weights,  # From Step 4
    callbacks=callbacks
)

"""Model Evaluation"""

# Load the best model
from tensorflow.keras.models import load_model
model = load_model('best_model.h5')

# Evaluate on validation set
val_loss, val_acc = model.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc*100:.2f}%")

"""Making Predictions"""

from tensorflow.keras.preprocessing import image

def predict_mask(image_path):
    # Load and preprocess image
    img = image.load_img(image_path, target_size=IMG_SIZE)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0  # Rescale to match training

    # Make prediction
    pred = model.predict(img_array)[0]
    class_names = list(train_generator.class_indices.keys())
    return class_names[np.argmax(pred)], np.max(pred)

# Example usage
image_path = 'test_image.jpg'  # Replace with your image path
pred_class, confidence = predict_mask(image_path)
print(f"Prediction: {pred_class} ({confidence*100:.2f}%)")





# from google.colab import drive
# drive.mount('/content/drive')

# from google.colab import files
# files.download('/content/dataset_cnn')  # Replace with your file's name
# files.download('/content/best_model.h5')
# files.download('/content/annotations.csv')

